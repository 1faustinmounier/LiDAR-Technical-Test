import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
import pandas as pd
import numpy as np
from src import clustering, metrics, interpolation
import plotly.graph_objects as go

st.set_page_config(page_title="D√©tection de c√¢bles cat√©naires LiDAR", layout="wide")

# --- Barre lat√©rale de navigation ---
menu = [
    "üè† Accueil",
    "‚öôÔ∏è Exploration & Optimisation",
    "üìà Visualisation 3D",
    "üìä Pr√©sentation Finale"
]
page = st.sidebar.radio("Navigation", menu)

data_dir = "data"
parquet_files = [f for f in os.listdir(data_dir) if f.endswith('.parquet')]

# --- Page d'accueil ---
if page == "üè† Accueil":
    st.title("D√©tection et Clustering de C√¢bles Cat√©naires dans un Nuage de Points LiDAR")
    st.markdown("""
    Ce projet a pour objectif de d√©tecter automatiquement les c√¢bles cat√©naires dans des nuages de points LiDAR 3D.
    
    **Pipeline g√©n√©ral :**
    1. Chargement d'un fichier .parquet contenant les points (x, y, z)
    2. Application de diff√©rentes m√©thodes de clustering (RANSAC, DBSCAN, Agglom√©ratif, etc.)
    3. Optimisation automatique des param√®tres pour chaque m√©thode
    4. Calcul de m√©triques de qualit√© (bruit, continuit√©, lin√©arit√©, compacit√©...)
    5. Interpolation de chaque c√¢ble d√©tect√© pour g√©n√©rer une courbe continue (cat√©naire ou lin√©aire)
    6. Visualisation interactive 3D
    
    **Pourquoi ?**
    - Automatiser l'analyse d'infrastructures √©lectriques
    - G√©rer le bruit et la complexit√© des donn√©es LiDAR
    - Fournir des outils d'√©valuation et d'am√©lioration des algorithmes
    
    _Utilisez le menu √† gauche pour explorer les fonctionnalit√©s._
    """)
    st.info("Projet r√©alis√© pour un test technique Data Science - 2024")

# --- Exploration & Optimisation ---
elif page == "‚öôÔ∏è Exploration & Optimisation":
    st.title("Exploration & Optimisation des M√©thodes de Clustering")
    st.markdown("""
    - S√©lectionnez un fichier de donn√©es LiDAR (.parquet)
    - Choisissez une m√©thode de clustering
    - Lancez l'optimisation automatique des param√®tres
    - Visualisez les m√©triques de qualit√© et l'interpolation des c√¢bles
    """)

    # 1. S√©lection du fichier
    file_choice = st.selectbox("Choisissez un fichier .parquet", parquet_files, key="optim_file")
    df = pd.read_parquet(os.path.join(data_dir, file_choice))
    points = df[['x', 'y', 'z']].to_numpy()

    # 2. Choix de la m√©thode
    method_options = {
        "RANSAC": "RANSAC (robuste, lin√©aire)",
        "Directional": "DBSCAN directionnel (densit√© + orientation)",
        "Agglomerative": "Clustering agglom√©ratif",
        "Hough2D": "Hough 2D (projection)",
        "GraphKNN": "Graphe k-NN (composantes)"
    }
    method = st.selectbox("M√©thode de clustering", list(method_options.keys()), format_func=lambda x: method_options[x])

    # 3. Param√®tres manuels (affich√©s en permanence)
    st.subheader("Param√®tres de la m√©thode")
    if method == "RANSAC":
        resid = st.slider("Seuil RANSAC", 0.001, 0.2, 0.05, 0.001)
        min_s = st.slider("Min samples", 10, 100, 40, 5)
        max_it = st.slider("Max it√©rations", 1, 50, 10, 1)
        manual_params = {'residual_threshold': resid, 'min_samples': min_s, 'max_iter': max_it}
    elif method == "Directional":
        k = st.slider("k voisins", 3, 20, 10, 1)
        eps = st.slider("eps DBSCAN", 0.01, 0.5, 0.2, 0.01)
        min_s = st.slider("Min samples", 2, 20, 5, 1)
        manual_params = {'k': k, 'eps': eps, 'min_samples': min_s}
    elif method == "Agglomerative":
        n_clusters = st.slider("Nombre de clusters", 2, 10, 3, 1)
        linkage = st.selectbox("M√©thode de linkage", ["ward", "complete", "average", "single"])
        manual_params = {'n_clusters': n_clusters, 'linkage': linkage}
    elif method == "Hough2D":
        res = st.slider("R√©solution grille", 0.005, 0.1, 0.05, 0.005)
        num_peaks = st.slider("Nombre de pics", 1, 10, 4, 1)
        manual_params = {'res': res, 'num_peaks': num_peaks}
    elif method == "GraphKNN":
        k = st.slider("k voisins", 2, 20, 6, 1)
        manual_params = {'k': k}

    # 4. Ex√©cution avec param√®tres manuels (affich√© en permanence)
    st.subheader("R√©sultats avec param√®tres manuels")
    try:
        if method == "RANSAC":
            labels = clustering.run_ransac(points, **manual_params)
        elif method == "Directional":
            labels = clustering.run_direction_clustering(points, **manual_params)
        elif method == "Agglomerative":
            labels = clustering.run_agglomerative(points, **manual_params)
        elif method == "Hough2D":
            labels = clustering.run_hough2d(points, **manual_params)
        elif method == "GraphKNN":
            labels = clustering.run_graph_knn(points, **manual_params)
        
        # Calcul des m√©triques
        metrics_result = metrics.evaluate_segmentation(points, labels, 3, 6)
        
        # Affichage des r√©sultats
        col1, col2 = st.columns(2)
        with col1:
            st.write("**M√©triques de qualit√© :**")
            st.write(f"- Nombre de clusters : {metrics_result['n_clusters']}")
            st.write(f"- Score global : {metrics_result['score_global']:.2f}")
            st.write(f"- Pourcentage de bruit : {metrics_result['pct_bruit']:.1%}")
            st.write(f"- Courbure moyenne : {metrics_result['courbure']:.3f}")
        
        with col2:
            st.write("**Param√®tres utilis√©s :**")
            for key, value in manual_params.items():
                st.write(f"- {key} : {value}")
        
        # Interpolation automatique
        st.subheader("Interpolation des c√¢bles d√©tect√©s")
        interp_method = st.selectbox("M√©thode d'interpolation", ["linear", "catenary"], format_func=lambda x: "Lin√©aire" if x=="linear" else "Cat√©naire")
        interpolated_cables = interpolation.interpolate_all_cables(points, labels, method=interp_method)
        st.write(f"{len(interpolated_cables)} c√¢bles interpol√©s.")
        
        # Affichage rapide (2D)
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots(figsize=(7,5))
        for label, cable in interpolated_cables.items():
            ax.plot(cable[:,1], cable[:,2], label=f"C√¢ble {label}")
        ax.set_xlabel('y')
        ax.set_ylabel('z')
        ax.set_title("Courbes interpol√©es (projection YZ)")
        ax.legend()
        st.pyplot(fig)
        
        # Sauvegarde des r√©sultats pour la page 3D
        st.session_state['file_choice'] = file_choice
        st.session_state['points'] = points
        st.session_state['labels'] = labels
        st.session_state['interpolated_cables'] = interpolated_cables
        
    except Exception as e:
        st.error(f"Erreur lors de l'ex√©cution : {str(e)}")

    # 5. Optimisation automatique (optionnelle)
    st.subheader("Optimisation automatique des param√®tres")
    target_min = st.number_input("Nombre de c√¢bles min (cible)", 1, 20, 3, 1)
    target_max = st.number_input("Nombre de c√¢bles max (cible)", 1, 20, 6, 1)
    run_optim = st.button("Lancer l'optimisation automatique")

    if run_optim:
        with st.spinner("Optimisation en cours..."):
            # Grilles de param√®tres simples pour chaque m√©thode
            if method == "RANSAC":
                param_grid = [
                    (resid, min_s, max_it)
                    for resid in np.linspace(0.01, 0.2, 8)
                    for min_s in [20, 40, 60]
                    for max_it in [5, 10, 20]
                ]
                for resid, min_s, max_it in param_grid:
                    labels = clustering.run_ransac(points, residual_threshold=resid, min_samples=min_s, max_iter=max_it)
                    m = metrics.evaluate_segmentation(points, labels, target_min, target_max)
                    score = m['score_global']
                    if score > best_score:
                        best_score = score
                        best_labels = labels
                        best_metrics = m
                        best_params = {'residual_threshold': resid, 'min_samples': min_s, 'max_iter': max_it}
            elif method == "Directional":
                param_grid = [
                    (k, eps, min_s)
                    for k in [5, 10, 15]
                    for eps in np.linspace(0.05, 0.3, 6)
                    for min_s in [3, 5, 8]
                ]
                for k, eps, min_s in param_grid:
                    labels = clustering.run_direction_clustering(points, k=k, eps=eps, min_samples=min_s)
                    m = metrics.evaluate_segmentation(points, labels, target_min, target_max)
                    score = m['score_global']
                    if score > best_score:
                        best_score = score
                        best_labels = labels
                        best_metrics = m
                        best_params = {'k': k, 'eps': eps, 'min_samples': min_s}
            elif method == "Agglomerative":
                for n_clusters in range(target_min, target_max+1):
                    for linkage in ["ward", "complete", "average", "single"]:
                        try:
                            labels = clustering.run_agglomerative(points, n_clusters=n_clusters, linkage=linkage)
                        except Exception:
                            continue
                        m = metrics.evaluate_segmentation(points, labels, target_min, target_max)
                        score = m['score_global']
                        if score > best_score:
                            best_score = score
                            best_labels = labels
                            best_metrics = m
                            best_params = {'n_clusters': n_clusters, 'linkage': linkage}
            elif method == "Hough2D":
                for res in np.linspace(0.01, 0.1, 5):
                    for num_peaks in range(target_min, target_max+1):
                        labels = clustering.run_hough2d(points, res=res, num_peaks=num_peaks)
                        m = metrics.evaluate_segmentation(points, labels, target_min, target_max)
                        score = m['score_global']
                        if score > best_score:
                            best_score = score
                            best_labels = labels
                            best_metrics = m
                            best_params = {'res': res, 'num_peaks': num_peaks}
            elif method == "GraphKNN":
                for k in range(3, 15):
                    labels = clustering.run_graph_knn(points, k=k)
                    m = metrics.evaluate_segmentation(points, labels, target_min, target_max)
                    score = m['score_global']
                    if score > best_score:
                        best_score = score
                        best_labels = labels
                        best_metrics = m
                        best_params = {'k': k}

        if best_labels is not None:
            st.success(f"Meilleure segmentation trouv√©e (score={best_score:.2f})")
            st.write("**Param√®tres optimaux :**", best_params)
            st.write("**M√©triques de qualit√© :**", best_metrics)
        else:
            st.error("Aucune segmentation satisfaisante trouv√©e.")

# --- Visualisation 3D ---
elif page == "üìà Visualisation 3D":
    st.title("Visualisation 3D des C√¢bles D√©tect√©s et Interpol√©s")
    st.markdown("""
    - S√©lectionnez le fichier de donn√©es √† visualiser
    - Affichez les points clusteris√©s, les courbes interpol√©es et les cat√©naires simul√©es
    - Utilisez les cases √† cocher pour activer/d√©sactiver chaque √©l√©ment
    """)
    # S√©lection du fichier √† visualiser
    file_choice_3d = st.selectbox("Fichier .parquet √† visualiser", parquet_files, key="visu_file")
    # Si on a d√©j√† optimis√© ce fichier, on r√©cup√®re les r√©sultats, sinon on recharge les points
    if st.session_state.get('file_choice') == file_choice_3d:
        points = st.session_state.get('points', None)
        labels = st.session_state.get('labels', None)
        interpolated_cables = st.session_state.get('interpolated_cables', None)
    else:
        df = pd.read_parquet(os.path.join(data_dir, file_choice_3d))
        points = df[['x', 'y', 'z']].to_numpy()
        labels = None
        interpolated_cables = None

    # Contr√¥les d'affichage
    show_clustered = st.checkbox("Afficher les points clusteris√©s", value=True)
    show_interpolated = st.checkbox("Afficher les courbes interpol√©es", value=True)
    show_catenaries = st.checkbox("Afficher les cat√©naires simul√©es (extr√©mit√©s)", value=False)

    # Cr√©ation de la figure 3D
    fig = go.Figure()

    # Points clusteris√©s
    if show_clustered and labels is not None:
        unique_labels = np.unique(labels[labels != -1])
        for label in unique_labels:
            mask = labels == label
            fig.add_trace(go.Scatter3d(
                x=points[mask, 0], y=points[mask, 1], z=points[mask, 2],
                mode='markers', name=f'Cluster {label}',
                marker=dict(size=2, opacity=0.7)
            ))

    # Courbes interpol√©es
    if show_interpolated and interpolated_cables is not None:
        for label, cable in interpolated_cables.items():
            fig.add_trace(go.Scatter3d(
                x=cable[:, 0], y=cable[:, 1], z=cable[:, 2],
                mode='lines', name=f'Interpol√© {label}',
                line=dict(width=3, color='red')
            ))

    # Cat√©naires simul√©es
    if show_catenaries and interpolated_cables is not None:
        for label, cable in interpolated_cables.items():
            if len(cable) > 1:
                start_point = cable[0]
                end_point = cable[-1]
                catenary = interpolation.generate_catenary_curve(start_point, end_point, num_points=50, sag=0.1)
                fig.add_trace(go.Scatter3d(
                    x=catenary[:, 0], y=catenary[:, 1], z=catenary[:, 2],
                    mode='lines', name=f'Cat√©naire {label}',
                    line=dict(width=2, color='green', dash='dash')
                ))

    # Configuration de la figure
    fig.update_layout(
        title=f"Visualisation 3D - {file_choice_3d}",
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z'
        ),
        width=800,
        height=600
    )

    st.plotly_chart(fig, use_container_width=True)

# --- Pr√©sentation Finale ---
elif page == "üìä Pr√©sentation Finale":
    st.title("Pr√©sentation Finale : Pipeline Adaptatif")
    
    st.markdown("""
    ## üéØ Objectif du Module
    
    Ce module apporte un **outil de recherche et d'adaptation** pour la d√©tection de c√¢bles dans des nuages de points LiDAR, 
    permettant de s'adapter √† diff√©rents cas d'usage selon la complexit√© des donn√©es.
    """)
    
    st.markdown("""
    ## üìä M√©thodes de Clustering Disponibles
    
    ### 1. **RANSAC** 
    - **Id√©al pour** : C√¢bles bien s√©par√©s, peu de bruit
    - **Param√®tres cl√©s** : `residual_threshold`, `min_samples`
    - **Avantages** : Robuste aux outliers, d√©tection automatique du nombre de c√¢bles
    
    ### 2. **Clustering Directionnel (DBSCAN + PCA)**
    - **Id√©al pour** : C√¢bles avec orientations similaires
    - **Param√®tres cl√©s** : `k` (voisins), `eps`, `min_samples`
    - **Avantages** : Prend en compte la g√©om√©trie locale
    
    ### 3. **Clustering Agglom√©ratif** ‚≠ê
    - **Id√©al pour** : Fichiers easy et medium - **M√âTHODE RECOMMAND√âE**
    - **Param√®tres cl√©s** : `n_clusters`, `linkage` (ward/complete/average)
    - **Avantages** : Contr√¥le du nombre de c√¢bles, r√©sultats stables
    
    ### 4. **Hough 2D (projection)**
    - **Id√©al pour** : Projections 2D de c√¢bles lin√©aires
    - **Param√®tres cl√©s** : `res` (r√©solution), `num_peaks`
    - **Avantages** : D√©tection de lignes droites
    
    ### 5. **Graphe (kNN)**
    - **Id√©al pour** : C√¢bles connect√©s spatialement
    - **Param√®tres cl√©s** : `k` (voisins)
    - **Avantages** : Connectivit√© naturelle
    """)
    
    st.markdown("""
    ## üéØ Adaptation selon le Type de Fichier
    
    ### **Fichiers Easy** ‚úÖ
    ```
    M√©thode recommand√©e : Clustering Agglom√©ratif
    - n_clusters = 3
    - linkage = "ward"
    - R√©sultats : Courbes lisses, peu de zigzags
    ```
    
    ### **Fichiers Medium/Hard/Extrahard** ‚ö†Ô∏è
    ```
    M√©thodes alternatives :
    - RANSAC avec seuil adaptatif
    - Clustering directionnel avec eps r√©duit
    - Combinaison de m√©thodes
    ```
    """)
    
    st.markdown("""
    ## üìà M√©triques de Qualit√©
    
    ### **M√©triques Calcul√©es :**
    - **Courbure moyenne** : Angle entre vecteurs successifs
    - **Compacit√© lat√©rale** : Moyenne des distances perpendiculaires aux reconstructions PCA
    - **Continuit√©** : Longueur axiale / longueur totale
    - **Lin√©arit√©** : R¬≤ de la r√©gression PCA
    
    ### **Score Global :**
    ```python
    score = 2 * (clusters_dans_cible) + 
            (1 - pct_bruit * 10) + 
            (1 - cv_taille * 5) + 
            continuite + linearite + 
            (1 - compacite_laterale * 5) +
            (1 - courbure)
    ```
    """)
    
    st.markdown("""
    ## üîß Am√©liorations Apport√©es
    
    ### **Interpolation Anti-Zigzag :**
    - Tri par distance cumul√©e le long de la courbe PCA
    - √âvite les retours en arri√®re et les sauts
    - Courbes plus naturelles et lisses
    
    ### **Robustesse :**
    - Try/except individuels pour chaque m√©thode
    - Gestion des cas limites (clusters vides, points isol√©s)
    - Messages de debug pour le d√©veloppement
    """)
    
    st.markdown("""
    ## ‚ö†Ô∏è Limitations et Probl√®mes Identifi√©s
    
    ### **Cas Probl√©matiques :**
    
    1. **2+ Sets de C√¢bles Parall√®les**
       - Les m√©thodes peuvent m√©langer les c√¢bles de diff√©rents sets
       - Solution : Pr√©traitement par zones g√©ographiques
    
    2. **C√¢bles Tr√®s Proches**
       - Risque de fusion de clusters
       - Solution : R√©duction du `eps` ou augmentation du `min_samples`
    
    3. **Bruit √âlev√©**
       - Points parasites perturbent le clustering
       - Solution : Filtrage pr√©alable ou RANSAC
    
    4. **C√¢bles Courb√©s Complexes**
       - Zigzags possibles m√™me avec tri optimis√©
       - Solution : Interpolation cat√©naire ou splines
    """)
    
    st.markdown("""
    ## üéØ Conclusion
    
    ### **Points Forts :**
    - ‚úÖ Pipeline modulaire et extensible
    - ‚úÖ Adaptation automatique selon la complexit√©
    - ‚úÖ M√©triques de qualit√© robustes
    - ‚úÖ Interface utilisateur intuitive
    - ‚úÖ Interpolation anti-zigzag efficace
    
    ### **Am√©liorations Futures :**
    - üîÑ Algorithme de suivi directionnel (track following)
    - üîÑ Pr√©traitement par zones g√©ographiques
    - üîÑ Interpolation par splines cubiques
    - üîÑ Validation crois√©e des m√©thodes
    
    ### **Recommandations d'Usage :**
    1. **Commencez par le clustering agglom√©ratif** (m√©thode la plus stable)
    2. **Ajustez les param√®tres selon les m√©triques** affich√©es
    3. **Testez plusieurs m√©thodes** si les r√©sultats ne sont pas satisfaisants
    4. **Utilisez l'optimisation automatique** pour trouver les meilleurs param√®tres
    
    ---
    
    **Ce module constitue une base solide pour la d√©tection de c√¢bles LiDAR, avec la flexibilit√© n√©cessaire pour s'adapter √† diff√©rents cas d'usage tout en maintenant une qualit√© de r√©sultats √©lev√©e.**
    """) 